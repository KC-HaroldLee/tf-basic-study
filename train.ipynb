{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Train code - SHSH version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### init by KK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>샘플 이미지 예 (왼 : ori, 오른 lbl)</p>\n",
    "<div style=\"display: inline-block;\">\n",
    "    <img src='./dataset/ori/Abyssinian_1.jpg' width = 300 height = 300 alt='ori_img_sample' style=\"display: inline-block;\">\n",
    "    <img src='./dataset/lbl/Abyssinian_1.png' width = 300 height = 300 alt='ori_img_sample' style=\"display: inline-block;\">\n",
    "</div>\n",
    "\n",
    "<p>sample data : <a href=https://www.robots.ox.ac.uk/~vgg/data/pets/>https://www.robots.ox.ac.uk/~vgg/data/pets/</a></p>\n",
    "<p>위 데이터의 lbl이미지는 원래는 1채널, onehot 이미지이나(검은 이미지) 임의의 색으로 바꾸어 데이터 셋을 새로 만들었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 basic import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u>또한 같은 기능으로 사용되는데 서로 다른 함수를 호출하는 경우도 있었습니다... 속도의 차이인지 작성한 사람이 달라서 그런지 모르겠지만 일단 함수는 그대로 두었습니다.</u></p>또한 변수명을 짓는 스타일이 서로 달라서 혼동되는 변수명도 있습니다. 주의하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 tf import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 17:42:56.548169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-25 17:42:56.607735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-25 17:42:56.608031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa # 0.11.2?\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU')) # GPU 유뮤 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 sm import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n",
      "Segmentation Models: using `tf.keras` framework.\n",
      "tf.keras\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "\n",
    "import segmentation_models as sm # pip install segmentation_models\n",
    "sm.set_framework('tf.keras')\n",
    "print(sm.framework())\n",
    "\n",
    "from segmentation_models.losses import * \n",
    "from segmentation_models.base import Loss\n",
    "from segmentation_models.base import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 tf.keras.layers import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "# check call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Global Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 사용될 전역변수들을 설정합니다. (모델 관련 전역변수는 아래에 있습니다.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_LABELMAP = {\n",
    "    # Background\n",
    "    0 : {'RGB' : (50,50,50), 'name': 'bg', 'target': 0},\n",
    "\n",
    "    # animal\n",
    "    1 : {'RGB' : (120,50,75), 'name': 'animal', 'target': 1},\n",
    "    2 : {'RGB' : (128,255,128), 'name': 'border', 'target': 2},\n",
    "#     3 : {'RGB' : (50,50,80), 'name': 'border', 'target': 1} # Merge의 예\n",
    "}\n",
    "\n",
    "# RGB_LABELMAP : 학습하기 전 Onehot이미지를 만들거나, 학습 중 혹은 테스트 결과로 반환되는 Onehot이미지를\n",
    "#               다시 RGB이미지로 만들 때 사용됩니다. target은 합쳐야 할(merge) 클래스를 설정할 때도 사용됩니다.\n",
    "\n",
    "TARGET_CLASSES  = [0,1,2]\n",
    "# TARGET_CLASSES  = [0,2]\n",
    "\n",
    "# TARGET_CLASSES : 학습에 해당되는 클래스리스트 입니다. 다만 RGB_LABELMAP의 내부 dict의 key인 'target'과는 다른 의미입니다.\n",
    "# 1번 클래스를 2번 클래스로 Merge를 했더라도 2번위치도 학습해야하므로 [0,1,2]가 되어야합니다.\n",
    "\n",
    "CLASS_CNT = len(TARGET_CLASSES) \n",
    "# 이전에는 수동으로 int를 입력했었으나 이제는 리스트의 길이를 사용하는 걸로 바꾸었습니다.\n",
    "\n",
    "# COLOR_MODE = ['RGB']\n",
    "SRC_CHANNELS = 3 # 예전에 NSXY이미지가 있었던 시절 '4'일때도 있어서 따로 정의한 변수입니다. 사실 아래에 '3'으로 입력해도 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Image Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 RGB2Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   RGB2Onehot(): 일반 RGB이미지를  OneHot이미지로 바꿉니다. 만약 학습되는 클래스가 3개라면 (h,w,3), 10개라면 (h,w,10) numpy.ndarray를 반환합니다.\n",
    "'''\n",
    "\n",
    "def RGB2OneHot(input_image:np.ndarray, label_map:dict, bChannel:bool = False) -> np.ndarray :\n",
    "    # global CLASS_CNT\n",
    "    reshape_image = input_image.reshape((-1,3))\n",
    "\n",
    "    if bChannel :\n",
    "        dense = np.zeros(reshape_image.shape[:1]+(CLASS_CNT,), np.uint8)\n",
    "    else : \n",
    "        dense = np.zeros(reshape_image.shape[:1]+(1,), np.uint8)\n",
    "    \n",
    "#     print(f'\\t{dense.shape}')\n",
    "\n",
    "    for label, sub_dict in label_map.items():\n",
    "        target_label = sub_dict['target']\n",
    "\n",
    "        if (target_label not in TARGET_CLASSES) :\n",
    "            print(f'label is not in ... -> BG')\n",
    "            target_label = 0\n",
    "        \n",
    "        color = list(sub_dict['RGB'])\n",
    "        label_name = sub_dict['name']\n",
    "\n",
    "#         print(reshape_image[0])\n",
    "#         print(color)\n",
    "\n",
    "        if bChannel :\n",
    "            temp_np = np.zeros(CLASS_CNT)\n",
    "            temp_np[target_label] = 1\n",
    "            dense[np.all(reshape_image == color, axis=-1)] = temp_np\n",
    "        else :\n",
    "            dense[np.all(reshape_image == color, axis=-1)] = target_label\n",
    "            \n",
    "    if bChannel :\n",
    "        dense = dense.reshape((input_image.shape[:2] + (CLASS_CNT,)))\n",
    "    else :\n",
    "        dense = dense.reshape((input_image.shape[:2] + (1,)))\n",
    "            \n",
    "    return dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 onehot2RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   onehot2RGB(): OneHot이미지를 RGB이미지로 바꿉니다. (제 기억엔) 학습에는 쓰이지 않고 결과를 볼때만 사용됩니다.\n",
    "'''\n",
    "\n",
    "def onehot2RGB(input_image:np.ndarray, label_map:dict, bChannel:bool) ->np.ndarray :\n",
    "    rgb_lbl = np.zeros(input_image.shape+(3,), np.uint8)\n",
    "\n",
    "    if bChannel == True :\n",
    "        rgb_lbl = np.zeros(input_image.shape[:2] + (3,), np.uint8)\n",
    "        input_image = input_image.argmax(-1)\n",
    "\n",
    "    for label, sub_dict in label_map.items() :\n",
    "        color = sub_dict['RGB']\n",
    "        label_name = sub_dict['name']\n",
    "\n",
    "        rgb_lbl[input_image == label] = color\n",
    "\n",
    "    rgb_lbl = rgb_lbl.reshape(input_image.shape[:2]+ (3,))\n",
    "\n",
    "    return rgb_lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 show_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    학습에 쓰이는 Color를 단순히 출력하는 함수\n",
    "'''\n",
    "\n",
    "def show_color() :\n",
    "    cell = np.zeros((3,3,3), np.uint8)\n",
    "    idx = 0\n",
    "\n",
    "    f, axes = plt.subplots(1, CLASS_CNT, figsize=(18,4))\n",
    "\n",
    "    for label, sub_dict in RGB_LABELMAP.items():\n",
    "        if label in TARGET_CLASSES :\n",
    "            color = sub_dict['RGB']\n",
    "            label_name = sub_dict['name']\n",
    "            target_num = sub_dict['target']\n",
    "            cell[:] = color\n",
    "\n",
    "            axes[idx].imshow(cell)\n",
    "            axes[idx].set_xlabel(f'{label_name} : {label}')\n",
    "            idx=idx+1\n",
    "        else :\n",
    "            pass\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_color()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 show_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    show_mask() : 마스크 이미지를 만들때(create_mask()) 사용되는 함수인데, 이름이 왜 show인지는...\n",
    "'''\n",
    "def show_mask(pred_val:np.ndarray, num=0):\n",
    "    print('pred val.shape = ', pred_val.shape)\n",
    "    b, w, h, ch = pred_val.shape \n",
    "\n",
    "    f, axes = plt.subplots(1, ch, figsize =(18, 6))\n",
    "    for idx in range(ch) :\n",
    "        axes[idx].imshow(pred_val[0][:,:,idx] * 255, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 create_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    create_mask() : 마스크 이미지를 만듭니다.\n",
    "'''\n",
    "\n",
    "def create_mask(pred_val:np.ndarray, num=0):\n",
    "    \n",
    "    show_mask(pred_val)\n",
    "\n",
    "    pred_mask = tf.argmax(pred_val, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 calculate_class_iou()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    각 클래스별 iou를 구하여 반환합니다.\n",
    "'''\n",
    "\n",
    "def calculate_class_iou(gt_labels, pred_labels, class_list = None, preview = False) :\n",
    "    \n",
    "    img_size = pred_labels.shape[:2]\n",
    "\n",
    "    if class_list is None or len(class_list) == 0 :\n",
    "        class_list = np.arange(CLASS_CNT)\n",
    "\n",
    "    gt_selected_labels = np.zeros(img_size, dtype='uint8')\n",
    "    pred_selected_labels = np.zeros(img_size, dtype='uint8')\n",
    "\n",
    "    for class_num in class_list :\n",
    "        np.place(gt_selected_labels, gt_labels == class_num, 255)\n",
    "        np.place(pred_selected_labels, pred_labels == class_num, 255)\n",
    "\n",
    "    iou_list = []\n",
    "\n",
    "    for class_num in class_list :\n",
    "        gt_cur_labels = np.zeros(img_size, dtype=np.uint8)\n",
    "        pred_cur_labels = np.zeros(img_size, dtype=np.uint8)\n",
    "\n",
    "        np.place(gt_cur_labels, gt_labels == class_num, 1)\n",
    "        np.place(pred_cur_labels, pred_labels == class_num, 1)\n",
    "\n",
    "        intersection = gt_cur_labels * pred_cur_labels\n",
    "        union = gt_cur_labels + pred_cur_labels - intersection\n",
    "\n",
    "        gt_sum = gt_cur_labels.sum()\n",
    "        intersection_sum = intersection.sum()\n",
    "        union_sum = union.sum()\n",
    "\n",
    "        if union_sum == 0 :\n",
    "            iou = 0\n",
    "        else :\n",
    "            iou = intersection_sum / union_sum\n",
    "        iou = np.round(iou, 2)\n",
    "\n",
    "        print(f'class [{class_num}]={iou}\\t({intersection_sum}/{gt_sum}/{union_sum})')\n",
    "        iou_list.append(iou)\n",
    "\n",
    "    return iou_list, class_list\n",
    "\n",
    "        # cnt_gt, labels_gt, stats_gt, centroids_gt = cv.connectedComponentsWithStats(gt_selected_labels)\n",
    "        # cnt_pred, labels_pred, stats_pred, centroids_pred = cv.connectedComponentsWithStats(pred_selected_labels)\n",
    "\n",
    "        # gt_num_blobs = len(np.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 set dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './dataset/'\n",
    "\n",
    "ORI_EXT = '.jpg' # 오리지날 이미지 확장명\n",
    "LBL_EXT = '.png' # 레이블 이미지 확장명\n",
    "\n",
    "ori_path = base_path + 'ori/'\n",
    "lbl_path = base_path + 'lbl/'\n",
    "\n",
    "ori_list = [item for item in os.listdir(ori_path) if ORI_EXT in item]\n",
    "lbl_list = [item for item in os.listdir(lbl_path) if LBL_EXT in item]\n",
    "\n",
    "print('all image\\'s cnt :', len(ori_list))\n",
    "print('all label\\'s cnt :', len(lbl_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (320,320,3)\n",
    "print(INPUT_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list_txt_path = base_path + 'val_list.txt'\n",
    "print(val_list_txt_path)\n",
    "print('\\tval_list_txt is exist :', os.path.isfile(val_list_txt_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 valid data utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 load_valid_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   load_valid_label_list() : 미리 작성한 텍스트파일에서 검증파일 리스트를 불러옵니다. \n",
    "'''\n",
    "\n",
    "def load_valid_label_list(val_txt_path:str) -> list:\n",
    "    val_label_list = []\n",
    "\n",
    "    f = open(val_txt_path)\n",
    "    while(True) :\n",
    "        line = f.readline().replace('\\n', '')\n",
    "        '''\n",
    "            custom commentary\n",
    "            '#'으로 시작하는 line은 무시하고\n",
    "            '@'으로 시작하는 line은 '@'뒤를 무시\n",
    "            ./dataset/val_list.txt 에  예시가 있어요.\n",
    "        ''' \n",
    "        if '#' in line :\n",
    "            continue\n",
    "        if '@'in line :\n",
    "            line = line.split('@')[0]\n",
    "        if not line :\n",
    "            break\n",
    "        else :\n",
    "            val_label_list.append(line)\n",
    "    f.close()\n",
    "\n",
    "    return val_label_list \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. load_train_file_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   load_train_file_list() : 전체셋 - 검증셋 = 학습셋\n",
    "'''\n",
    "\n",
    "def load_train_label_list(all_label_file_list:list, valid_label_list:list) -> list:\n",
    "    except_list = valid_label_list\n",
    "\n",
    "    load_train_label_list = [item for item in all_label_file_list if item not in except_list]\n",
    "\n",
    "    return load_train_label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. make Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>아래 함수들에 문제가 살짝 있습니다...</p>\n",
    "<p>(조금 이야기가 길어요... 사실 이거 때문에 주석을 단다고 한건데...)</p>\n",
    "<br>\n",
    "<p>데이터의 크기가 많아지면서 OOM이 뜨다보니</p>\n",
    "<br>\n",
    "<p>\"야, 데이터제너레이터 좀 만들어봐라\"</p>\n",
    "<br>\n",
    "<p>라고 하셔서 DataGenerator를 만들었습니다.</p>\n",
    "<p>학습이 시작되면 각 Batch마다 \"__len__()\"번 만큼 \"__getitem__()\"을 호출하여 데이터를 가져옵니다.(numpy.ndarray로 변환합니다)</p>\n",
    "<p>그렇게 한 번에 불러오는 데이터의 양을 적게 해서 OOM을 피하는 건데</p>\n",
    "<br>\n",
    "<p>\"야, 굳이 이미지를 numpy.ndarray로 변환 해놓은 데이터를 날리고 또 변환하는 건 너무 오래 걸리고 답답하다. 그러니까...\"</p>\n",
    "<br>\n",
    "<p>라고 하셔서 모든 이미지를 각각 numpy.ndarray 로 변환 후 하나의 <u>리스트</u>에 담아두고</p>\n",
    "<p>인덱스로 간단히 가져와서 이미지를 numpy.ndarray로 바꾸는 작업을 처음 한 번만 진행해도 되어서 학습속도를 높일 수 있었습니다.</p>\n",
    "<br>\n",
    "<p>하지만 생각해보니 수많은 numpy.ndarray을 담을 수 있는 <u>리스트</u>는 컴퓨터에 일반 RAM에 저장되는 거 같아요.</p>\n",
    "<p>OOM이라고 뜨진 않지만 컴퓨터가 죽으려고 했거든요. (16GB RAM)</p>\n",
    "<p>생각해보니 우리가 지금까지 본 OOM은 그래픽카드의 VRAM이 터진다는 의미였어요.</p>\n",
    "<p>단지 우리가 사용해 오던 워크스테이션 PC의 RAM의 용량이 엄청 커서 우리가 느끼지 못했던 거였네요.</p>\n",
    "<br>\n",
    "<p>일단은 폴더안에 파일을 줄이는 걸로 테스트만 가능하게끔 해놨습니다.\n",
    "<br>\n",
    "<p>그러면 다시 DataGenerator를 되돌여야하는데 (학습 속도는 다시 느려지겠지만) 그건 아직 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 mk_ori_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    mk_ori_list() : original 이미지를 numpy.ndarray로 바꾸어 리스트에 담아 반환합니다.\n",
    "                    위에서 언급했듯 RAM에 무리가 갈거 같아서 데이터의 수를 줄였습니다.\n",
    "'''\n",
    "\n",
    "def mk_ori_list(file_name_list:list, output_type:str = 'list') :\n",
    "    if output_type == 'list' : \n",
    "        ori_img_list = []\n",
    "\n",
    "        for idx, file_name in enumerate(file_name_list) :\n",
    "            print(f'\\rProcessing... \\\"{file_name}\\\" \\t', end='')\n",
    "            out = []\n",
    "            if True : \n",
    "                raw_ori_img_path = os.path.join(ori_path, file_name.replace(LBL_EXT, ORI_EXT))\n",
    "                raw_ori_src = cv.imread(raw_ori_img_path)\n",
    "\n",
    "                raw_ori_src = cv.cvtColor(raw_ori_src, cv.COLOR_BGR2RGB)\n",
    "                \n",
    "                raw_ori_src = raw_ori_src.astype(np.float32)\n",
    "                raw_ori_src = cv.resize(raw_ori_src, INPUT_SHAPE[:2], interpolation=cv.INTER_NEAREST)\n",
    "                raw_ori_src = raw_ori_src / 255.0\n",
    "\n",
    "                out.append(raw_ori_src)\n",
    "            \n",
    "            final_ori_src = np.concatenate(out, -1)\n",
    "            ori_img_list.append(final_ori_src)\n",
    "\n",
    "        print('')\n",
    "    \n",
    "    return ori_img_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 mk_lbl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    mk_lbl_list() : original 이미지를 numpy.ndarray로 바꾸어 리스트에 담아 반환합니다.\n",
    "                    위에서 언급했듯 RAM에 무리가 갈거 같아서 데이터의 수를 줄였습니다.\n",
    "'''\n",
    "\n",
    "def mk_lbl_list(file_name_list:list, output_type:str = 'list') :\n",
    "    if output_type == 'list' : \n",
    "        lbl_img_list = []\n",
    "\n",
    "        for idx, file_name in enumerate(file_name_list) :\n",
    "            print(f'\\rProcessing... {file_name} \\t', end='')\n",
    "            \n",
    "            raw_lbl_img_path = os.path.join(lbl_path, file_name)\n",
    "            raw_lbl_src = cv.imread(raw_lbl_img_path)\n",
    "\n",
    "            raw_lbl_src = cv.cvtColor(raw_lbl_src, cv.COLOR_BGR2RGB)\n",
    "\n",
    "            final_lbl_src  = RGB2OneHot(raw_lbl_src, RGB_LABELMAP, bChannel=True)\n",
    "            final_lbl_src = cv.resize(final_lbl_src, INPUT_SHAPE[:2], interpolation=cv.INTER_NEAREST)\n",
    "            final_lbl_src = final_lbl_src.astype(np.float32)\n",
    "            \n",
    "            lbl_img_list.append(final_lbl_src)\n",
    "\n",
    "        print('')\n",
    "    \n",
    "    return lbl_img_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustomDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    CustomDataGenerator : 만들어 놓긴 했지만 이미 만들어진 리스트에 담겨있는 numpy.ndarray을 인덱싱해서 가져오는 역할만 할 뿐입니다.\n",
    "                        일반 RAM이 터지지 않게 다시 바꾸려면 \n",
    "                        self.train_x_set 에는 파일경로 리스트를 (현재 : numpy.ndarray가 담겨있는 리스트)\n",
    "                        self.train_y_set 도 위와 동일\n",
    "                        \n",
    "                        __getitem__() 은 cv.imread()등으로 이미지파일을 numpy.ndarray로 바꾸는 과정이 필요합니다. \n",
    "                            (mk_ori_list() 안의 함수들이 들어갈거에요. mk_ori_list()만들어질 때 __getitem__()안의 내용을 가져왔었으니.)\n",
    "'''\n",
    "\n",
    "class CustomDataGenerator(Sequence) :\n",
    "    def __init__(self, train_x_set:list, train_y_set:list, batch_size:int=16, channel_num:int=3, image_size:tuple=(0,0), shuffle:bool=False, rotation_range:float=0, brighteness_range:float=0, v_flip:bool=False, h_flip:bool=False) :\n",
    "        self.train_x_set = train_x_set\n",
    "        self.train_y_set = train_y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.channel_num = channel_num\n",
    "        self.shuffle = shuffle\n",
    "        self.image_size = image_size\n",
    "        self.rotation_range = rotation_range\n",
    "        self.brighteness_range = brighteness_range\n",
    "        self.v_flip = v_flip\n",
    "        self.h_flip = h_flip\n",
    "\n",
    "        self.indices = np.arange(len(train_x_set))\n",
    "\n",
    "    def __len__(self) :\n",
    "        return math.ceil(len(self.train_x_set) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        start_idx = idx*self.batch_size\n",
    "        end_idx = (idx+1)*self.batch_size\n",
    "\n",
    "        curr_indices = self.indices[start_idx:end_idx]\n",
    "\n",
    "        batch_ori_list = [self.train_x_set[idx] for idx in curr_indices]\n",
    "        batch_lbl_list = [self.train_y_set[idx] for idx in curr_indices]\n",
    "\n",
    "        result_ori_list = []\n",
    "        result_lbl_list = []\n",
    "\n",
    "        for idx, _img in enumerate(batch_ori_list) :\n",
    "\n",
    "            ori_img = batch_ori_list[idx]\n",
    "            lbl_img = batch_lbl_list[idx]\n",
    "\n",
    "            tf_ori_img = tf.convert_to_tensor(ori_img)\n",
    "            tf_lbl_img = tf.convert_to_tensor(lbl_img)\n",
    "\n",
    "            # aug pass\n",
    "\n",
    "            result_ori_list.append(tf.expand_dims(tf_ori_img, 0))\n",
    "            result_lbl_list.append(tf.expand_dims(tf_lbl_img, 0))\n",
    "\n",
    "        result_ori_list = tf.concat(result_ori_list, 0)\n",
    "        result_lbl_list = tf.concat(result_lbl_list, 0)\n",
    "        \n",
    "        return result_ori_list, result_lbl_list\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = load_valid_label_list(val_list_txt_path)\n",
    "len(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = load_train_label_list(lbl_list, val_list)\n",
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    여기서 일반 RAM이 터집니당...\n",
    "'''\n",
    "\n",
    "mk_train_ori_list_start = time.time()\n",
    "train_ori_list = mk_ori_list(train_list, output_type='list')\n",
    "print('mk_train_ori_list took', time.time() - mk_train_ori_list_start)\n",
    "\n",
    "mk_train_lbl_list_start = time.time()\n",
    "train_lbl_list = mk_lbl_list(train_list, output_type='list')\n",
    "print('mk_train_lbl_list took', time.time() - mk_train_lbl_list_start)\n",
    "\n",
    "mk_val_ori_list_start = time.time()\n",
    "val_ori_list = mk_ori_list(val_list, output_type='list')\n",
    "print('mk_val_ori_list took', time.time() - mk_val_ori_list_start)\n",
    "\n",
    "mk_val_lbl_list_start = time.time()\n",
    "val_lbl_list = mk_lbl_list(val_list, output_type='list')\n",
    "print('mk_val_lbl_list took', time.time() - mk_val_lbl_list_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ori_list[0].dtype)\n",
    "print(train_lbl_list[0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SET Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATION = 'softmax'\n",
    "FROM_LOGITS = False\n",
    "OPTIMIZER = 'RMSprop' # Adam\n",
    "LR = 0.0005\n",
    "SMOOTH = 1e-5\n",
    "\n",
    "BACKBONE = 'efficientnetb4'\n",
    "ENC_FREEZE = False\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "ENC_WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 train fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 show_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(model, filename:str, class_list:list) :\n",
    "    print(f'show_prediction -> {filename}')\n",
    "    ori_img_path = ori_path + filename.replace(LBL_EXT, ORI_EXT)\n",
    "    lbl_img_path = lbl_path + filename.replace(ORI_EXT, LBL_EXT)\n",
    "\n",
    "    raw_ori_src = cv.imread(ori_img_path)\n",
    "    raw_ori_src = cv.resize(raw_ori_src, (INPUT_SHAPE[:2]), interpolation=cv.INTER_NEAREST)\n",
    "    raw_ori_src = cv.cvtColor(raw_ori_src, cv.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    out = []\n",
    "    out.append(raw_ori_src)\n",
    "\n",
    "    final_ori_src = np.concatenate(out, -1)\n",
    "    print(f'ori.shape -> {final_ori_src.shape}')\n",
    "\n",
    "    raw_lbl_src = cv.imread(lbl_img_path)\n",
    "    raw_lbl_src = cv.cvtColor(raw_lbl_src, cv.COLOR_BGR2RGB)\n",
    "    raw_lbl_src = cv.resize(raw_lbl_src, (INPUT_SHAPE[:2]), interpolation=cv.INTER_NEAREST)\n",
    "    onehot_lbl_src = RGB2OneHot(raw_lbl_src, RGB_LABELMAP)\n",
    "\n",
    "    input_src = tf.expand_dims(final_ori_src, 0)\n",
    "    pred = model.predict(input_src, batch_size = 1)\n",
    "    pred_mask = create_mask(pred)\n",
    "\n",
    "    # preview\n",
    "    f, axes = plt.subplots(1,3, figsize=(18,8))\n",
    "    axes[0].imshow(final_ori_src)\n",
    "    # axes[1].imshow(onehot2RGB(raw_lbl_src[:,:,0], RGB_LABELMAP, bChannel=False))\n",
    "    axes[1].imshow(raw_lbl_src)\n",
    "    axes[2].imshow(onehot2RGB(pred_mask[:,:,0], RGB_LABELMAP, bChannel=False))\n",
    "    plt.show()\n",
    "\n",
    "    iou_list, class_list = calculate_class_iou(onehot_lbl_src, pred_mask, class_list, preview=False)\n",
    "    print(iou_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 DisplayCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs = None) :\n",
    "        loss = np.round(logs['loss'], 3)\n",
    "        iou = np.round(logs['iou_score'], 3)\n",
    "        val_loss = np.round(logs['val_loss'], 3)\n",
    "        val_iou = np.round(logs['val_iou_score'], 3)\n",
    "\n",
    "        print(f'\\nEpoch[{epoch+1}] loss = {loss}, iou ={iou}, val_loss = {val_loss}, val_iou = {val_iou}')\n",
    "\n",
    "        print('train data ====>')\n",
    "        for idx in range(1) :\n",
    "            show_prediction(self.model, train_list[random.randint(0, len(train_list)-1)], TARGET_CLASSES[1:])\n",
    "        print('val data ====>')\n",
    "        for idx in range(1) :\n",
    "            show_prediction(self.model, val_list[random.randint(0, len(val_list)-1)], TARGET_CLASSES[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './models/'\n",
    "try :\n",
    "    os.mkdir(model_save_path)\n",
    "except :\n",
    "    print('already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_val_loss_cheakpoint = ModelCheckpoint(filepath=model_save_path+f'saved_models_'+'VAL_LOSS'+'_{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_loss', verbose=1, mode='max', save_best_only=True)\n",
    "cb_val_iou_score_cheakpoint = ModelCheckpoint(filepath=model_save_path+f'saved_models_'+'VAL_IOU_SCORE'+'_{epoch:02d}-{val_loss:.4f}.hdf5', monitor='val_iou_socre', verbose=1, mode='max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDiceLoss(Loss) :\n",
    "    def __init__(self, beta=1, class_weights=None, class_indices=None, per_image=False, smooth=1e-5):\n",
    "        super().__init__(name='dice_loss')\n",
    "        self.beta = beta\n",
    "        self.class_weights = class_weights\n",
    "        self.class_indices = class_indices\n",
    "        self.per_image = per_image\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def __call__(self, gt, pred) :\n",
    "        return 1 - F.f_score(gt, pred, beta=self.beta, class_weights=self.class_weights, class_indexes=self.class_indices, smooth=self.smooth, per_image=self.per_image, **self.submodules)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    작성은 했지만 어떻게 사용하는지 몰라요 ㅠㅠ\n",
    "'''\n",
    "\n",
    "def weight_change(base_model, change_model, num_channles = 3):\n",
    "    base_model_weight = base_model.get_weights()\n",
    "\n",
    "    new_weight = np.zeros((3,3,num_channles,32))\n",
    "    for idx in range(num_channles):\n",
    "        new_weight[:,:,idx,:] = base_model_weight[idx][:,:,idx,:]\n",
    "\n",
    "    base_model_weight[0] = new_weight\n",
    "\n",
    "    change_model.set_weights(base_model_weight)\n",
    "    return change_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "\n",
    "    if SRC_CHANNELS == 3 :\n",
    "        base_model = sm.Unet(BACKBONE, input_shape=INPUT_SHAPE, classes=CLASS_CNT, encoder_weights=ENC_WEIGHTS, activation=ACTIVATION, encoder_freeze=ENC_FREEZE)\n",
    "\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "    inp = Input(shape=INPUT_SHAPE[:2]+(SRC_CHANNELS,)) # 3channel color\n",
    "    print(f'input_shape -> {INPUT_SHAPE[:2]+(SRC_CHANNELS,)}')\n",
    "\n",
    "    conv2d = Conv2D(SRC_CHANNELS, (1,1))(inp)\n",
    "    out = base_model(conv2d)\n",
    "\n",
    "    model = Model(inp, out)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if OPTIMIZER == 'Adam':\n",
    "    opt = keras.optimizers.Adam(learning_rate=LR)\n",
    "if OPTIMIZER == 'RMSprop':\n",
    "    opt = keras.optimizers.RMSprop(learning_rate=LR)\n",
    "\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model cre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt,\n",
    "    # loss = sm.losses.DiceLoss() + sm.losses.CategoricalCELoss(),\n",
    "    # loss = sm.losses.CategoricalCELoss(class_weights=np.array([7, 16, 14, 7, 7, 14, 14, 14, 7])/100)\n",
    "    loss = CustomDiceLoss(),\n",
    "    # loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy', sm.metrics.IOUScore(), sm.metrics.FScore()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].layers[-2].output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdg_train = CustomDataGenerator(train_ori_list, train_lbl_list, image_size=INPUT_SHAPE, shuffle= False, channel_num=3, batch_size=2)\n",
    "cdg_val = CustomDataGenerator(val_ori_list, val_lbl_list, image_size=INPUT_SHAPE, shuffle= False, channel_num=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ? . TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ?.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = cdg_train.__getitem__(2)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(18,18))\n",
    "axes[0].imshow(test_x[0].numpy())\n",
    "axes[1].imshow(onehot2RGB(test_y[0].numpy(), RGB_LABELMAP, bChannel=True))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print(cv.imwrite('./test.png', test_y[0].numpy()))\n",
    "\n",
    "# print(test_y[0].numpy()[200][200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cdg_train.__getitem__(0)[0].numpy().dtype)\n",
    "print(cdg_train.__getitem__(0)[1].numpy().dtype)\n",
    "print(cdg_val.__getitem__(0)[0].numpy().dtype)\n",
    "print(cdg_val.__getitem__(0)[1].numpy().dtype)\n",
    "\n",
    "print(cdg_train.__getitem__(0)[0].numpy().shape)\n",
    "print(cdg_train.__getitem__(0)[1].numpy().shape)\n",
    "print(cdg_val.__getitem__(0)[0].numpy().shape)\n",
    "print(cdg_val.__getitem__(0)[1].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = time.time()\n",
    "history = model.fit(cdg_train, epochs=200, validation_data=cdg_val,\n",
    "                    callbacks=[DisplayCallback(model)]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_TEST",
   "language": "python",
   "name": "tf_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
